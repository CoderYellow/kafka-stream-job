

status = warn

appender.console.type = Console
appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss} %-5p [%t] %c{1}:%L - %m%n
appender.console.layout.type = PatternLayout
appender.console.name = consoleLogger

# Configure root logger
rootLogger.level = info
rootLogger.appenderRef.console.ref = consoleLogger
#spark default
#rootLogger.appenderRef.console.ref = console




#logger.awssdk.name: software.amazon.awssdk
#logger.awssdk.level: trace
#logger.awssdk.appenderRef.console.ref: consoleLogger
#logger.awssdk.additivity: false
#
#logger.awssdk.request.name: software.amazon.awssdk.request
#logger.awssdk.request.level: trace
#logger.awssdk.request.appenderRef.console.ref: consoleLogger
#logger.awssdk.request.additivity: false
#
#logger.awssdk.http.name: software.amazon.awssdk.http
#logger.awssdk.http.level: trace
#logger.awssdk.http.appenderRef.console.ref: consoleLogger
#logger.awssdk.http.additivity: false
#
#logger.awssdk.signer.name: software.amazon.awssdk.auth.signer
#logger.awssdk.signer.level: trace
#logger.awssdk.signer.appenderRef.console.ref: consoleLogger
#logger.awssdk.signer.additivity: false

# SHOW MICRO-BATCH EXECUTION
log4j.logger.org.apache.spark.sql.execution.streaming.MicroBatchExecution=DEBUG

# SHOW OFFSET LOGIC (reading, planning, committing)
log4j.logger.org.apache.spark.sql.execution.streaming.StreamExecution=DEBUG

# SHOW SOURCE OFFSET PROCESSING (Kafka)
log4j.logger.org.apache.spark.sql.kafka010.KafkaOffsetReader=DEBUG
log4j.logger.org.apache.spark.sql.kafka010.KafkaSource=DEBUG

# SHOW CHECKPOINT WRITING
log4j.logger.org.apache.spark.sql.execution.streaming.CheckpointFileManager=DEBUG
log4j.logger.org.apache.spark.sql.execution.streaming.HDFSMetadataLog=DEBUG

# SHOW STATE STORE (if any stateful operators are used)
log4j.logger.org.apache.spark.sql.execution.streaming.state=DEBUG

# SHOW ICEBERG COMMIT STEPS
log4j.logger.org.apache.iceberg=DEBUG
log4j.logger.org.apache.iceberg.spark=DEBUG
